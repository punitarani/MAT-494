{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/punitarani/MAT-494/blob/master/3.7%20Neural%20Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.7 Neural Networks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A neural network is a collection of connected layers of nodes to loosely model the neurons in the brain.\n",
    "\n",
    "### How does a Neural Network work?\n",
    "\n",
    "- The input layer receives the input data.\n",
    "- The hidden layers transform the input data into the output data.\n",
    "- The output layer produces the output data.\n",
    "- The weights and biases are updated using the backpropagation algorithm.\n",
    "- The loss function is used to measure the performance of the model.\n",
    "- The loss function is minimized using the gradient descent algorithm.\n",
    "- The model is tuned using the hyperparameters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## High-Level Model\n",
    "\n",
    "$ \\text{Input} \\rightarrow \\text{Hidden Layer} \\rightarrow \\text{Output} $\n",
    "\n",
    "$ \\text{Input} \\rightarrow \\Sigma f(x) \\rightarrow \\text{Output} $\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neuron (Perceptron)\n",
    "\n",
    "A Neural Network consists of Neurons, which are the basic building blocks of a neural network.\n",
    "A Neuron is a single node in a neural network.\n",
    "A Neuron is defined as:\n",
    "\n",
    "$y_k = \\varphi(\\sum_{i=1}^n w_{ki} x_i + b_k)$\n",
    "\n",
    "where:\n",
    "- $y_k$ is the output of the $k$-th perceptron.\n",
    "- $x_i$ is the input of the $i$-th perceptron.\n",
    "- $w_{ki}$ is the weight of the $k$-th perceptron.\n",
    "- $b_k$ is the bias of the $k$-th perceptron.\n",
    "- $\\varphi$ is the activation or transfer function.\n",
    "\n",
    "\n",
    "### Activation Function\n",
    "\n",
    "The activation function for a neuron is used to transform the input data into the output data.\n",
    "The activation function is defined as:\n",
    "\n",
    "$u = \\sum_{i=1}^n w_i x_i + b$\n",
    "\n",
    "$y = \\varphi(u)$\n",
    "\n",
    "where:\n",
    "- $u$ is the weighted sum of the inputs.\n",
    "- $y$ is the output of the neuron.\n",
    "- $x_i$ is the input of the $i$-th neuron.\n",
    "- $w_i$ is the weight of the $i$-th neuron.\n",
    "- $b$ is the bias of the neuron.\n",
    "\n",
    "#### Step Function\n",
    "\n",
    "The step function is a simple activation function that returns 1 if the input is greater than 0, otherwise it returns 0.\n",
    "\n",
    "$y = \\begin{cases} 1 & \\text{if } u > 0 \\\\ 0 & \\text{otherwise} \\end{cases}$\n",
    "\n",
    "#### ReLU Function\n",
    "\n",
    "ReLU stands for Rectified Linear Unit.\n",
    "It is one of the most popular activation functions.\n",
    "ReLU performs a linear transformation of the input data.\n",
    "\n",
    "$y = \\begin{cases} u & \\text{if } u > 0 \\\\ 0 & \\text{otherwise} \\end{cases}$\n",
    "\n",
    "#### Sigmoid Function\n",
    "\n",
    "The sigmoid function is a smooth activation function that returns a value between 0 and 1.\n",
    "\n",
    "$y = \\frac{1}{1 + e^{-u}}$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
