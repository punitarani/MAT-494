{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/punitarani/MAT-494/blob/master/3.3%20Unconstrained%20Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.3 Unconstrained Optimization\n",
    "\n",
    "Key Concepts\n",
    "\n",
    "- Local and Global Minimizers\n",
    "- Convexity\n",
    "- Gradient Descent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Minimizers\n",
    "\n",
    "### Global Minimizer\n",
    "\n",
    "$f(x*) \\le f(x), \\forall x \\in R^d$\n",
    "\n",
    "Finding the global minimizer involves comparing $f(x*)$ with ever f(x) value in the input space.\n",
    "This can be a complicated process for a large input space.\n",
    "Consequently, only in limited and special cases can a $f(x*)$ be proven as the global minimizer.\n",
    "\n",
    "### Local Minimizer\n",
    "\n",
    "$f(x*) \\le f(x), \\forall x \\in B_{\\delta}(x*) \\backslash \\{x*\\}$\n",
    "\n",
    "A local minimizer finds $f(x*)$ such that it is the global minimizer in a neighborhood $N$ surrounding $x*$.\n",
    "\n",
    "### Descent Direction\n",
    "\n",
    "$f(x_0 + \\alpha v) < f(x_0), \\forall \\alpha \\in (0, \\alpha*)$\n",
    "\n",
    "The directional derivative gives a criterion for descent directions for a continuously differentiable function.\n",
    "\n",
    "$\\frac{\\delta f(x_0)}{\\delta v} = \\nabla f(x_0)^T v < 0$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convexity\n",
    "\n",
    "A function is convex iff a line segment between 2 points lies above the graph between the points.\n",
    "\n",
    "$f((1-\\alpha)x + \\alpha y) \\le (1-alpha)f(x) + \\alpha f(y),  for$\n",
    "$x, y \\in R, and$\n",
    "$\\alpha \\in [0, 1]$\n",
    "\n",
    "The convexity of a function can be proven with its Hessian.\n",
    "\n",
    "$H_f(x) = \\frac{1}{2}[P + P^T]$\n",
    "\n",
    "So, f is convex iff $\\frac{1}{2}[P + P^T]$ has non-negative eigenvalues.\n",
    "\n",
    "### First-order Convexity\n",
    "\n",
    "$f(y) \\ge f(x) + \\nabla f(x)^T(x-w)$\n",
    "\n",
    "### Second-order Convexity\n",
    "\n",
    "f is convex iff $H_f(x)$ is PSD for $x \\in R^d$\n",
    "\n",
    "### Global Minimizers of Convex Functions\n",
    "\n",
    "For a convex function, minimizers must follow: $\\nabla f(x_0) = 0$.\n",
    "Which means that is $\\nabla f(x_0) = 0$, then $x_0$ is a global minimizer.\n",
    "\n",
    "#### Global Minimizer\n",
    "\n",
    "$x^* = -Q \\Lambda^{-1} Q^T q$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
